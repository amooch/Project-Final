{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93343f03-78bd-428d-a1e1-a058f0023c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d56ba8b-9485-4003-937e-0d3575f6fb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4f26b4a-5de3-4124-bf1f-0a79e1887fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adrian Muchatibaya\\AppData\\Local\\Temp\\ipykernel_33740\\780400531.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['TotalCharges'].fillna(data['TotalCharges'].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Accuracy: 0.8106956933270232, Precision: 0.68125, Recall: 0.5696864111498258, F1: 0.6204933586337761\n",
      "Random Forest - Accuracy: 0.795551348793185, Precision: 0.678391959798995, Recall: 0.47038327526132406, F1: 0.5555555555555556\n",
      "Optimized Random Forest - Accuracy: 0.7993374349266446, Precision: 0.6681614349775785, Recall: 0.519163763066202, F1: 0.5843137254901961\n",
      "\n",
      "Important Features:\n",
      "MonthlyCharges      0.202422\n",
      "TotalCharges        0.199711\n",
      "tenure              0.179072\n",
      "Contract            0.126435\n",
      "OnlineSecurity      0.087446\n",
      "TechSupport         0.057221\n",
      "PaymentMethod       0.050234\n",
      "OnlineBackup        0.036475\n",
      "InternetService     0.034473\n",
      "PaperlessBilling    0.026511\n",
      "dtype: float64\n",
      "\n",
      "Based on the evaluation metrics, the Optimized Random Forest model is the best-performing model.\n",
      "The top features contributing to customer churn prediction are:\n",
      "MonthlyCharges    0.202422\n",
      "TotalCharges      0.199711\n",
      "tenure            0.179072\n",
      "Contract          0.126435\n",
      "OnlineSecurity    0.087446\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "data['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce')\n",
    "data['TotalCharges'].fillna(data['TotalCharges'].mean(), inplace=True)\n",
    "\n",
    "for column in data.select_dtypes(include=['object']):\n",
    "    if column != 'customerID':\n",
    "        data[column] = LabelEncoder().fit_transform(data[column])\n",
    "\n",
    "# Splitting dataset\n",
    "X = data.drop(['customerID', 'Churn'], axis=1)\n",
    "y = data['Churn']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Training and evaluating models\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_preds = logreg.predict(X_test)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_preds = rf.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "logreg_accuracy = accuracy_score(y_test, logreg_preds)\n",
    "logreg_precision = precision_score(y_test, logreg_preds)\n",
    "logreg_recall = recall_score(y_test, logreg_preds)\n",
    "logreg_f1 = f1_score(y_test, logreg_preds)\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, rf_preds)\n",
    "rf_precision = precision_score(y_test, rf_preds)\n",
    "rf_recall = recall_score(y_test, rf_preds)\n",
    "rf_f1 = f1_score(y_test, rf_preds)\n",
    "\n",
    "print(f\"Logistic Regression - Accuracy: {logreg_accuracy}, Precision: {logreg_precision}, Recall: {logreg_recall}, F1: {logreg_f1}\")\n",
    "print(f\"Random Forest - Accuracy: {rf_accuracy}, Precision: {rf_precision}, Recall: {rf_recall}, F1: {rf_f1}\")\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {'n_estimators': [10, 50, 100], 'max_depth': [None, 10, 20]}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Feature selection\n",
    "rfe = RFE(RandomForestClassifier(**best_params), n_features_to_select=10)\n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "rf_optimized = RandomForestClassifier(**best_params)\n",
    "rf_optimized.fit(X_train_rfe, y_train)\n",
    "rf_optimized_preds = rf_optimized.predict(X_test_rfe)\n",
    "\n",
    "rf_optimized_accuracy = accuracy_score(y_test, rf_optimized_preds)\n",
    "rf_optimized_precision = precision_score(y_test, rf_optimized_preds)\n",
    "rf_optimized_recall = recall_score(y_test, rf_optimized_preds)\n",
    "rf_optimized_f1 = f1_score(y_test, rf_optimized_preds)\n",
    "\n",
    "print(f\"Optimized Random Forest - Accuracy: {rf_optimized_accuracy}, Precision: {rf_optimized_precision}, Recall: {rf_optimized_recall}, F1: {rf_optimized_f1}\")\n",
    "\n",
    "\n",
    "#Identifying important features\n",
    "important_features = pd.Series(rf_optimized.feature_importances_, index=X.columns[rfe.support_])\n",
    "important_features = important_features.sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nImportant Features:\")\n",
    "print(important_features)\n",
    "\n",
    "\n",
    "#Conclusion\n",
    "print(\"\\nBased on the evaluation metrics, the Optimized Random Forest model is the best-performing model.\")\n",
    "print(\"The top features contributing to customer churn prediction are:\")\n",
    "print(important_features.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f378adc-d240-4890-a67d-d80a87c77cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
